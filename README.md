# D√©tection de fraudes bancaires par Machine Learning

## üìå Contexte
La fraude bancaire repr√©sente un enjeu majeur pour les institutions financi√®res :  
elle est rare mais g√©n√®re des pertes financi√®res importantes.  
Ce projet vise √† construire un **syst√®me de d√©tection de fraudes** √† partir de donn√©es transactionnelles r√©elles, en adoptant une d√©marche proche des pratiques industrielles.

---

## üéØ Objectifs du projet
- Analyser des donn√©es de transactions fortement d√©s√©quilibr√©es
- Construire un mod√®le de d√©tection de fraude fiable
- Comparer des approches simples et avanc√©es
- Optimiser la d√©cision finale via un seuil m√©tier
- Justifier chaque choix par des m√©triques adapt√©es

---

## üóÇÔ∏è Dataset
- **Source** : Credit Card Fraud Detection (Universit√© Libre de Bruxelles)
- **Taille** : 284 807 transactions
- **Fraudes** : 492 (‚âà 0.17 %)
- **Variables** :
  - V1 √† V28 : variables anonymis√©es (PCA)
  - Time : temps √©coul√©
  - Amount : montant de la transaction
  - Class : cible (0 = normal, 1 = fraude)

---

## üîç Analyse exploratoire (EDA)
- Mise en √©vidence du **fort d√©s√©quilibre des classes**
- Analyse des montants et du comportement temporel
- Identification des implications m√©tier :
  - l‚Äôaccuracy est trompeuse
  - priorit√© au recall et √† la Precision‚ÄìRecall AUC

---

## ü§ñ Mod√©lisation

### 1Ô∏è‚É£ Mod√®le baseline ‚Äî R√©gression Logistique
- Mod√®le simple et interpr√©table
- R√©sultats :
  - accuracy √©lev√©e mais recall fraude insuffisant
- Objectif : √©tablir un point de r√©f√©rence

### 2Ô∏è‚É£ R√©gression Logistique pond√©r√©e
- Gestion du d√©s√©quilibre via `class_weight="balanced"`
- Am√©lioration forte du recall
- Explosion des faux positifs
- Optimisation du seuil de d√©cision (seuil retenu : **0.85**)

### 3Ô∏è‚É£ Mod√®le avanc√© ‚Äî XGBoost
- Mod√®le non lin√©aire adapt√© aux donn√©es tabulaires
- Gestion native du d√©s√©quilibre (`scale_pos_weight`)
- Meilleure s√©paration des classes
- Optimisation du seuil (seuil retenu : **0.50**)

---

## üìä Comparaison finale des mod√®les

| Mod√®le | Seuil | Precision (Fraude) | Recall (Fraude) | Faux positifs | Faux n√©gatifs | ROC-AUC |
|------|------|-------------------|----------------|--------------|--------------|---------|
| Logistic Regression (pond√©r√©e) | 0.85 | 0.176 | 0.898 | 412 | 10 | ~0.97 |
| XGBoost | 0.50 | 0.837 | 0.837 | 16 | 16 | ~0.98 |

---

## üß† Conclusion m√©tier
- La r√©gression logistique n√©cessite un seuil tr√®s agressif pour atteindre un recall √©lev√©, ce qui d√©grade fortement l‚Äôexp√©rience client.
- XGBoost offre un **meilleur compromis precision / recall** avec beaucoup moins de faux positifs.
- L‚Äôoptimisation du seuil est une √©tape cl√© pour transformer un mod√®le ML en **outil de d√©cision op√©rationnel**.

üëâ **XGBoost est retenu comme solution finale**, car il est plus robuste et plus r√©aliste pour un d√©ploiement en production.

---

## üõ†Ô∏è Technologies utilis√©es
- Python
- Pandas / NumPy
- Scikit-learn
- XGBoost
- Matplotlib / Seaborn
- Jupyter Notebook

---

## üìä Dashboard interactif (Streamlit)

Un mini dashboard Streamlit a √©t√© d√©velopp√© afin de d√©montrer l‚Äôutilisation du mod√®le dans un contexte applicatif.

Fonctionnalit√©s :
- Chargement du mod√®le XGBoost entra√Æn√©
- Simulation de transactions
- Slider interactif pour le seuil de d√©cision
- Mode simplifi√© (Time, Amount) et mode expert (toutes les variables)
- Exemples pr√©charg√©s de transaction normale et frauduleuse

Le dashboard illustre la transformation d‚Äôun mod√®le de machine learning en outil de d√©cision exploitable.

---

## ‚ñ∂Ô∏è Lancer le projet
```bash
pip install -r requirements.txt
jupyter notebook